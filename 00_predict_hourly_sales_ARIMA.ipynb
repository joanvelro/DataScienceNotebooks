{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"00_predict_hourly_sales_ARIMA.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"J_g-65xP9fPn"},"source":["# Interbus Sales Prediction - ARIMA model"]},{"cell_type":"markdown","metadata":{"id":"fdhspfMU9fP2"},"source":["<img src=\"connective.png\" alt=\"drawing\" align=\"left\" width=\"300\"/> <img src=\"madlib.png\" alt=\"drawing\" align=\"left>\" width=\"150\"/> "]},{"cell_type":"markdown","metadata":{"id":"wLGpUuVO9fP3"},"source":["### [Documentation ](http://madlib.apache.org/docs/latest)"]},{"cell_type":"code","metadata":{"id":"EW0D0PwX9fP4"},"source":["from sqlalchemy.engine import create_engine\n","engine = create_engine(\"postgresql://gpadmin:pivotal@10.0.2.6:5432/gpadmin\")\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZeX1Z5Q9fP5"},"source":["%load_ext sql"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjUQWwMq9fP6"},"source":["%sql postgresql://gpadmin:pivotal@10.0.2.6:5432/gpadmin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfmHs8a_9fP9"},"source":["%sql select version()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqQffABo9fP-"},"source":["%%sql\n","drop table if exists madlib.ventas_timeseries_hourly;\n","\n","create table madlib.ventas_timeseries_hourly as (\n","SELECT count(*) as ventas, date_trunc('hour', ventas.\"fecha_venta\")::timestamp as fecha\n","from interbus.ventas\n","group by fecha\n","order by fecha);\n","\n","select count(*) from madlib.ventas_timeseries_hourly;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UTFYlMr9fP_"},"source":["# load SQL table with original data from databse as dataframe\n","sql = \"\"\"\n","select * from madlib.ventas_timeseries_hourly\n","order by fecha;\n","\"\"\"\n","df0 = pd.read_sql_query(sql, engine)\n","\n","# rename column of forecast\n","df0.rename(columns = {\"fecha\":\"dates\", \"ventas\":\"sales\"}, inplace=True)\n","\n","\n","# Obtain wich days are weekdays and non-working days  \n","df0['weekday'] = df0['dates'].dt.weekday\n","df0['weekend'] = 'False'\n","df0.loc[df0['weekday']==5, 'weekend'] = 'True'\n","df0.loc[df0['weekday']==6, 'weekend'] = 'True'\n","\n","\n","# set the index dataframe of the original results as the dates\n","if not isinstance(df0.index[0], pd.Timestamp):\n","    df0.set_index('dates', drop=True, inplace=True)\n","    \n","# set name of the day\n","days = {0:'Monday', 1:'Tuesday',2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n","df0['weekday'] = df0['weekday'].map(days)\n","\n","# set working days\n","df0.loc[:, 'type_day'] = 'working_day'\n","\n","# set not working days\n","df0.loc[df0['weekday']=='Saturday', 'type_day'] = 'non_working_day'\n","df0.loc[df0['weekday']=='Sunday', 'type_day'] = 'non_working_day'\n","\n","# set non_working days (from january to august)\n","\n","df0.loc['2019-01-01', ['type_day']] = 'non_working_day'\n","df0.loc['2019-01-06', ['type_day']] = 'non_working_day'\n","df0.loc['2019-04-09', ['type_day']] = 'non_working_day'\n","df0.loc['2019-05-01', ['type_day']] = 'non_working_day'\n","df0.loc['2019-05-02', ['type_day']] = 'non_working_day'\n","df0.loc['2019-08-15', ['type_day']] = 'non_working_day'\n","\n","# set holydays period of time \n","df0.loc[pd.date_range('2019-04-10', '2019-04-19'), ['type_day']] = 'holydays'\n","df0.loc[pd.date_range('2019-07-15', '2019-08-24'), ['type_day']] = 'holydays'\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJINOVqn9fQA"},"source":["# lleva mucho tiempo\n","# execute SQL quesry deleting table to be loaded\n","engine.execute(\"\"\"drop table if exists madlib.ventas_timeseries_hourly;\"\"\")\n","\n","# load dataframe results as a table in database\n","df0.to_sql('ventas_timeseries_hourly', schema='madlib', con=engine)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WW-Y4qN9fQB"},"source":["# group by type to cluster\n","df0_grouped = pd.DataFrame(df0.groupby(['weekday', 'weekend', 'type_day']).mean())\n","df0_grouped"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjWg4bZM9fQC"},"source":["%%sql \n","drop table if exists madlib.ventas_timeseries_hourly_output,\n","                     madlib.ventas_timeseries_hourly_output_residual,\n","                     madlib.ventas_timeseries_hourly_output_summary;\n","SELECT madlib.arima_train( 'madlib.ventas_timeseries_hourly',\n","                           'madlib.ventas_timeseries_hourly_output',\n","                           'dates',\n","                           'sales',\n","                           NULL,\n","                           FALSE,\n","                           ARRAY[6, 1, 1]\n","                         );\n","SELECT * FROM madlib.ventas_timeseries_hourly_output_summary;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_4JdAaf9fQD"},"source":["%%sql\n","SELECT * FROM madlib.ventas_timeseries_hourly_output;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmkXLbn69fQE"},"source":["%%sql\n","SELECT * FROM madlib.ventas_timeseries_hourly_output_residual;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmIrmzmx9fQG"},"source":["%%sql\n","drop table if exists madlib.ventas_timeseries_hourly_forecast_output;\n","SELECT madlib.arima_forecast( 'madlib.ventas_timeseries_hourly_output',\n","                              'madlib.ventas_timeseries_hourly_forecast_output',\n","                              130\n","                            );\n","SELECT * FROM madlib.ventas_timeseries_hourly_forecast_output\n","order by steps_ahead;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1NfBlPj9fQI"},"source":["# create an index of dates beginning with the last date of the original data up to \n","# the steps ahead forecasted\n","start_date = df0.index[len(df0)-2]\n","index = pd.date_range(start = start_date, periods = 130+1)\n","index = index[1:]\n","\n","# Load table results as dataframe\n","sql = \"\"\"\n","SELECT * FROM madlib.ventas_timeseries_hourly_forecast_output\n","order by steps_ahead;\n","\"\"\"\n","df = pd.read_sql_query(sql, engine)\n","\n","# eliminate Nan Values\n","df.dropna(inplace=True)\n","\n","# Sort by steps ahead\n","df.sort_values(by=['steps_ahead'], inplace=True)\n","\n","# include as colunm in the dataframe\n","df['dates'] = index \n","\n","df['weekday'] = df['dates'].dt.weekday\n","df['weekend'] = 'False'\n","df.loc[df['weekday']==5, 'weekend'] = 'True'\n","df.loc[df['weekday']==6, 'weekend'] = 'True'\n","\n","\n","# set data frame index as the dates\n","df.set_index('dates', drop=True, inplace=True)\n","\n","# set name of the day\n","df['weekday'] = df['weekday'].map(days)\n","    \n","# set non_working_days (from january to august)\n","df['type_day'] = 'working_day'\n","df.loc['2019-10-12', ['type_day']] = 'non_working_day'\n","df.loc['2019-11-01', ['type_day']] = 'non_working_day'\n","df.loc['2019-12-06', ['type_day']] = 'non_working_day'\n","df.loc['2019-12-08', ['type_day']] = 'non_working_day'\n","df.loc['2019-12-25', ['type_day']] = 'non_working_day'\n","\n","df.loc[df['weekday']=='Sunday', 'type_day'] = 'non_working_day'\n","df.loc[df['weekday']=='Saturday', 'type_day'] = 'non_working_day'\n","\n","# set holydays period of time \n","df.loc['2019-08-25 00:00:00': '2019-09-01 00:00:00', ['type_day']] = 'holydays'\n","df.loc['2019-12-06': '2019-12-08', ['type_day']] = 'holydays'\n","df.loc['2019-12-24': '2019-12-31', ['type_day']] = 'holydays'\n","\n","# eliminate column of steps ahead\n","df.drop(['steps_ahead'], inplace=True, axis=1)\n","\n","# rename column of forecast\n","df.rename(columns = {\"forecast_value\":\"ARIMA_forecast\", \"dates\":\"dates\"}, inplace=True)\n","\n","\n","df.head()\n","# Plot resutls\n","#df[['forecast_value']].plot(kind='line')\n","#plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CqfL7LX19fQK"},"source":["# mean value of sales in each day of the week\n","sales_mo = df0[df0['weekday']==days[0]].sales\n","sales_tu = df0[df0['weekday']==days[1]].sales\n","sales_we = df0[df0['weekday']==days[2]].sales\n","sales_th = df0[df0['weekday']==days[3]].sales\n","sales_fr = df0[df0['weekday']==days[4]].sales\n","sales_sa = df0[df0['weekday']==days[5]].sales\n","sales_su = df0[df0['weekday']==days[6]].sales\n","\n","# eliminate outliers\n","Q1 = np.quantile(sales_mo, 0.25)\n","Q3 = np.quantile(sales_mo, 0.75)\n","sales_mo = sales_mo[(sales_mo<(Q3+1.5*(Q3-Q1))) & (sales_mo>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_th, 0.25)\n","Q3 = np.quantile(sales_th, 0.75)\n","sales_th = sales_th[(sales_th<(Q3+1.5*(Q3-Q1))) & (sales_th>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_we, 0.25)\n","Q3 = np.quantile(sales_we, 0.75)\n","sales_we = sales_we[(sales_we<(Q3+1.5*(Q3-Q1))) & (sales_we>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_tu, 0.25)\n","Q3 = np.quantile(sales_tu, 0.75)\n","sales_tu = sales_tu[(sales_tu<(Q3+1.5*(Q3-Q1))) & (sales_tu>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_fr, 0.25)\n","Q3 = np.quantile(sales_fr, 0.75)\n","sales_fr = sales_fr[(sales_fr<(Q3+1.5*(Q3-Q1))) & (sales_fr>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_sa, 0.25)\n","Q3 = np.quantile(sales_sa, 0.75)\n","sales_sa = sales_sa[(sales_sa<(Q3+1.5*(Q3-Q1))) & (sales_sa>(Q1-1.5*(Q3-Q1)))]\n","\n","Q1 = np.quantile(sales_su, 0.25)\n","Q3 = np.quantile(sales_su, 0.75)\n","sales_su = sales_su[(sales_su<(Q3+1.5*(Q3-Q1))) & (sales_su>(Q1-1.5*(Q3-Q1)))]\n","\n","# extract mean values\n","mv_mo = sales_mo.mean()\n","mv_tu = sales_tu.mean()\n","mv_we = sales_we.mean()\n","mv_th = sales_th.mean()\n","mv_fr = sales_fr.mean()\n","mv_sa = sales_sa.mean()\n","mv_su = sales_su.mean()\n","\n","# extract standard deviation \n","sd_mo = sales_mo.std()\n","sd_tu = sales_tu.std()\n","sd_we = sales_we.std()\n","sd_th = sales_th.std()\n","sd_fr = sales_fr.std()\n","sd_sa = sales_sa.std()\n","sd_su = sales_su.std()\n","\n","# plot \n","mw_week = np.array([mv_mo, mv_tu, mv_we, mv_th, mv_fr, mv_sa, mv_su])\n","sd_week = np.array([sd_mo, sd_tu, sd_we, sd_th, sd_fr, sd_sa, sd_su])\n","x_label = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n","\n","plt.figure(figsize=(12,4))\n","plt.bar(x = x_label, height=mw_week)\n","plt.ylabel('Mean Value')\n","plt.show()\n","\n","plt.figure(figsize=(12,4))\n","plt.bar(x = x_label, height=sd_week)\n","plt.ylabel('Standard Deviation')\n","plt.show()\n","\n","plt.figure(figsize=(12,4))\n","plt.ylabel('Sales Boxplot')\n","plt.boxplot(x = [sales_mo, sales_th, sales_we, sales_tu, sales_fr, sales_sa, sales_su], labels = x_label )\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dk9xcD4W9fQM"},"source":["# create a copy of the resutls dataframe\n","df_aux = df.copy()\n","\n","# add mean value by the cluster weekday-weekend-type_day\n","for i in range(0,len(df0_grouped)):\n","    weekday = df0_grouped.iloc[i].name[0]\n","    weekend = df0_grouped.iloc[i].name[1]\n","    type_day = df0_grouped.iloc[i].name[2]\n","    \n","    df_aux.loc[(df_aux['weekday']==weekday) & (df_aux['weekend']==weekend) & (df_aux['type_day']==type_day), 'descriptive_cluster'] =  df0_grouped.iloc[i].sales\n","    \n","# add mean value by weekday\n","df_weekday = pd.DataFrame(df0.groupby(['weekday']).mean())\n","df_aux.loc[df_aux.weekday==days[0], 'descriptive_weekday'] = df_weekday.loc[days[0]].sales\n","df_aux.loc[df_aux.weekday==days[1], 'descriptive_weekday'] = df_weekday.loc[days[1]].sales\n","df_aux.loc[df_aux.weekday==days[2], 'descriptive_weekday'] = df_weekday.loc[days[2]].sales\n","df_aux.loc[df_aux.weekday==days[3], 'descriptive_weekday'] = df_weekday.loc[days[3]].sales\n","df_aux.loc[df_aux.weekday==days[4], 'descriptive_weekday'] = df_weekday.loc[days[4]].sales\n","df_aux.loc[df_aux.weekday==days[5], 'descriptive_weekday'] = df_weekday.loc[days[5]].sales\n","df_aux.loc[df_aux.weekday==days[6], 'descriptive_weekday'] = df_weekday.loc[days[6]].sales\n","\n","# add mean value by weekend\n","df_weekend = pd.DataFrame(df0.groupby(['weekend']).mean())\n","df_aux.loc[df_aux.weekend=='True', 'descriptive_weekend'] = df_weekend.sales[True]\n","df_aux.loc[df_aux.weekend=='False', 'descriptive_weekend'] = df_weekend.sales[False]\n","\n","\n","# add mean value by type_day\n","df_typeday = pd.DataFrame(df0.groupby(['type_day']).mean())\n","df_aux.loc[df_aux.type_day=='holydays', 'descriptive_typeday'] = df_typeday.sales['holydays']\n","df_aux.loc[df_aux.type_day=='non_working_day', 'descriptive_typeday'] = df_typeday.sales['non_working_day']\n","df_aux.loc[df_aux.type_day=='working_day', 'descriptive_typeday'] = df_typeday.sales['working_day']\n","\n","df_aux.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pwp80Kzs9fQO"},"source":["# parameters of the hybrid predictive model\n","# weight factor associated with ARIMA model, the bigger, the more important ARIMA is\n","coefs = [0.2, 0.4, 0.2, 0.4]\n","\n","# create new predictions based on descriptive model\n","df_aux['ARIMA_forecast_descriptive'] = df_aux['ARIMA_forecast']*coefs[0] + df_aux['descriptive_weekday']*coefs[1] + df_aux['descriptive_weekend']*coefs[2] + df_aux['descriptive_typeday']*coefs[3]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQIlDBcV9fQP"},"source":["\n","# Obtain wich days are weekdays and non-working days  \n","#df_aux['dates'] = df_aux.index\n","#df_aux['weekday'] = df_aux['dates'].dt.weekday\n","#df_aux['workday'] = np.logical_and(df_aux['weekday'] != 5, df_aux['weekday'] != 6)\n","#df_aux.drop(['dates'], inplace=True, axis=1)\n","\n","# set name of the day\n","#df_aux['weekday'] = df_aux['weekday'].map(days)\n","\n","\n","\n","# Obtain mean values for sales in weerkday and non-working days \n","#mv_wd = pd.read_sql_query('select sum(mv_wd) from interbus.ventas_time_series_stats', engine).iloc[0,0]\n","#mv_we = pd.read_sql_query('select sum(mv_we) from interbus.ventas_time_series_stats', engine).iloc[0,0]\n","#print('average daily sales in weekday:',mv_wd,'\\n', 'average daily sales in weekend:', mv_we)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoEvRiPR9fQP"},"source":["# Concat dataframes with real data and predictions\n","df_total = pd.concat([df0[['sales']], df_aux], axis=1)\n","\n","\n","# eliminate Nan values\n","df_total.fillna(0) \n","if 0 == 1:\n","    df_total.loc[df_total.sales.isna(), 'sales'] = 0\n","    df_total.loc[df_total.ARIMA_forecast.isna(), 'ARIMA_forecast'] = 0\n","    df_total.loc[df_total.ARIMA_forecast_descriptive.isna(), 'ARIMA_forecast_descriptive'] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ba3rDM8W9fQQ"},"source":["# Plot sales\n","#plt.figure(figsize=(12,8))\n","df_total[['sales', 'ARIMA_forecast','descriptive_cluster', 'descriptive_weekday','descriptive_typeday', 'ARIMA_forecast_descriptive']].plot(figsize=(14,4))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyVw-BgB9fQR"},"source":["# execute SQL quesry deleting table to be loaded\n","engine.execute(\"\"\"drop table if exists madlib.sales_prediction_hourly;\"\"\")\n","\n","# load dataframe results as a table in database\n","df_total.to_sql('sales_prediction_hourly', schema='madlib', con=engine)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0g8aJ0j9fQS"},"source":["df_total.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_c5xk9S9fQT"},"source":[""],"execution_count":null,"outputs":[]}]}