{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for regresion-based predictive models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each predictive model is trying to solve a problem with a different objective using a different dataset and hence, it is important to understand the context before choosing a metric.\n",
    "\n",
    "Usually, the answers to the following question help us choose the appropriate metric:\n",
    "\n",
    "    * Type of task: Regression? Classification?\n",
    "    * Business goal?\n",
    "    * What is the distribution of the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics\n",
    "\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Mean Absolute Error (MAE)\n",
    "* R Squared (R²)\n",
    "* Adjusted R Squared (R²)\n",
    "* Mean Square Percentage Error (MSPE)\n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* Root Mean Squared Logarithmic Error (RMSLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "It is perhaps the most simple and common metric for regression evaluation, but also probably the least useful. It is defined by the equation\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^N (y_1-\\hat{y}_i)^2 \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $y_ᵢ$ is the actual expected output and $\\hat{y}_i$ is the model’s prediction.\n",
    "\n",
    "MSE basically measures average squared error of our predictions. For each point, it calculates square difference between the predictions and the target and then average those values.\n",
    "\n",
    "* The higher this value, the worse the model is\n",
    "* It is never negative, since we’re squaring the individual prediction-wise errors before summing them, but would be zero for a perfect model .\n",
    "\n",
    "* __Advantage__: Useful if we have unexpected values that we should care about. Vey high or low value that we should pay attention.\n",
    "\n",
    "* __Disadvantage__: If we make a single very bad prediction, the squaring will make the error even worse and it may skew the metric towards overestimating the model’s badness. That is a particularly problematic behaviour if we have noisy data (that is, data that for whatever reason is not entirely reliable)\n",
    "\n",
    "even a “perfect” model may have a high MSE in that situation, so it becomes hard to judge how well the model is performing.\n",
    "\n",
    "On the other hand, if all the errors are small, or rather, smaller than 1, than the opposite effect is felt: we may underestimate the model’s badness.\n",
    "\n",
    "Note that if we want to have a constant prediction the best one will be the mean value of the target values. It can be found by setting the derivative of our total error with respect to that constant to zero, and find it from this equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "RMSE is just the square root of MSE. The square root is introduced to make scale of the errors to be the same as the scale of targets.\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^N (y_i-\\hat{y}_i)^2 } = \\sqrt{MSE}\n",
    "$$\n",
    "\n",
    "MSE and RMSE are similar in terms of their minimizers, every minimizer of MSE is also a minimizer for RMSE and vice versa since the square root is an non-decreasing function.\n",
    "\n",
    "$$\n",
    "MSE(a)>MSE(b)\\Rightarrow RMSE(a)>RMSE(b)\n",
    "$$\n",
    "\n",
    "It means that, if the target metric is RMSE, we still can compare our models using MSE,since MSE will order the models in the same way as RMSE. Thus we can optimize MSE instead of RMSE.\n",
    "\n",
    "MSE is a little bit easier to work with, so everybody uses MSE instead of RMSE. Also a little bit of difference between the two for gradient-based models.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial RMSE}{\\partial \\hat{y}_i} = \\frac{1}{2 \\sqrt{MSE} }  \\frac{\\partial MSE}{\\partial \\hat{y}_i } \n",
    "$$\n",
    "\n",
    "It means that travelling along MSE gradient is equivalent to traveling along RMSE gradient but with a different flowing rate and the flowing rate depends on MSE score itself.\n",
    "\n",
    "So even though RMSE and MSE are really similar in terms of models scoring, they can be not immediately interchangeable for gradient based methods. We will probably need to adjust some parameters like the learning rate.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "In MAE the error is calculated as an average of absolute differences between the target values and the predictions. The MAE is a linear score which means that all the individual differences are weighted equally in the average. For example, the difference between 10 and 0 will be twice the difference between 5 and 0. However, same is not true for RMSE. Mathematically, it is calculated using this formula:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^N |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "MAE penalizes huge errors larger in compararison with MSE. So, it’s not that sensitive to outliers as MSE.\n",
    "\n",
    "MAE is widely used in finance, where 10 euros error is usually exactly two times worse than 5 error. On the other hand, MSE metric thinks that 10 euros error is four times worse than 5 euros error.\n",
    "\n",
    "MAE is easier to justify than RMSE.\n",
    "\n",
    "The gradient of the MAE metric it is not defined as the gradiend is a step function and it takes -1 when $\\hat{y}$ is smaller than the target and +1 when it is larger. So formally, MAE is not differentiable, second derivative is zero everywhere and not defined in the point zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Squared ($R^2$)\n",
    "The coefficient of determination, or $R^2$, is another metric we may use to evaluate a model and it is closely related to MSE, but has the advantage of being scale-free — it does not matter if the output values are very large or very small, the $R^2$ is always going to be between $(-\\infty, 1)$\n",
    "\n",
    "It is hard to realize if our model is good or not by looking at the absolute values of MSE or RMSE. We would probably want to measure how much our model is better than the constant baseline.That is what makes $R^2$.\n",
    "Example:\n",
    "* MSE(a) = 32\n",
    "* RMSE(a) = 4\n",
    "* $R^2$(a) = 0.85\n",
    "\n",
    "___When R² is negative it means that the model is worse than predicting the mean.___\n",
    "\n",
    "$$\n",
    "R^2 = 1  - \\frac{MSE(model)}{MSE(baseline)} = \\frac{\\sigma_{y,\\hat{y}}}{\\sigma_{y} \\sigma_{\\hat{y}}}\n",
    "$$\n",
    "\n",
    "The MSE of the model is computed as above, while the MSE of the baseline is defined as:\n",
    "\n",
    "$$\n",
    "MSE(baseline) = \\frac{1}{n} \\sum_{i=1}^N (y_i-\\bar{y})^2 \n",
    "$$\n",
    "\n",
    "where the $\\bar{y}$ is the mean of the observed $y_i$\n",
    "\n",
    "baseline MSE can be thought of as the MSE that the simplest possible model would get. The simplest possible model would be to always predict the average of all samples. A value close to 1 indicates a model with close to zero error, and a value close to zero indicates a model very close to the baseline.\n",
    "\n",
    "___In conclusion, R² is the ratio between how good our model is vs how good is the naive mean model.___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "* MAE is more robust (less sensitive to outliers) than MSE \n",
    "* $R^2$ is good to know about the performance of a model in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2548.07\n",
      "RMSE: 50.48\n",
      "MAE: 41.23\n",
      "R2: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQNUlEQVR4nO3dbawcVR3H8d9sH7QLtBYKaiw7g8RKLYJArUajoig+vzGoiWuN8WFfEAiRhBrZRKPJEquvhKBmqTHqnTcq0USMSamVGBONtkJiES4hsnuLBtNWkDbbSx92fHHc+7w7M+3Onpkz30/CC4Zzm39z9Zd//ufMGS+KIgEAJq9iuwAAKCsCGAAsIYABwBICGAAsIYABwBICGAAsWZ1m8aZNm6IgCDIqBQDcdPDgwaNRFF269HmqAA6CQAcOHBhfVQBQAp7ndVd6zggCACwhgAHAEgIYACwhgAHAEgIYACwhgAE4LQxDBUGgSqWiIAgUhqHtkuakOoYGAEUShqEajYZ6vZ4kqdvtqtFoSJLq9brN0iTRAQNwWLPZnAvfgV6vp2azaamixQhgAM6amZlJ9XzSCGAAzqrVaqmeTxoBDMBZrVZL1Wp10bNqtapWq2WposUIYADOqtfrarfb8n1fnufJ93212+1cbMBJkpfmo5zbt2+PuIwHANLxPO9gFEXblz6nAwYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgALCEAAYASwhgAM567jnpuuskz5Ouuko6cMB2RYsRwAByKQxDBUGgSqWiIAgUhmHin/3Vr0zovvrV0mOPmWfT09KPf5xRsedote0CAGCpMAzVaDTU6/UkSd1uV41GQ5JUr9dX/JlTp6Rbb5V+8IPhf+6QH7XGi6Io8eLt27dHB/LWwwNwThAE6na7y577vq9Op7Po2ZNPSm97m/T888P/vCuvlPbvl2q1MReakOd5B6Mo2r70OSMIALkzMzMT+/z73zdjhq1bh4fvXXdJZ85ITz9tL3xHYQQBIHdqtdqKHfDmzdt0883Sww+P/vlHHpHe9a5sahsnOmAAudNqtVStVhc8ebukSIcP/21o+L7nPaYTjqJihK9EBwwgh+r1uvp9T1/4wjadOnXtyLX33SfddtuEChszAhhArjzxhPSGN0jSp4auWb9e+uMfB+uKixEEgFz4+tfNptqoUP3sZ6XZWem//y1++Ep0wAAsOnFC2rRJeuml0eu++U3py1+eTE2TRAcM5ND5vAVWBL/9rel2L7podPhOT5tNNRfDVyKAgdwZvAXW7XYVRdHcW2BFD+Eokj7xCRO8733v8HXvfKd09qxZv2XL5OqzgTfhgJxJ8xZYEfzzn9LmzfHrfvYz6ZZbsq/HBt6EAwoiyVtgRbBnj+l248L36FHT7boavqMQwEDO1Ia8MzvseZ6cPm2uffQ86YtfHL7u1ltN6EaRdMklk6svbwhgIGeWvwUmVatVtVotSxXFe/RRE7pr15qNs2H+9CcTuvffP7na8owABnKmXq+r3W7L9315niff99Vut4dew2jTXXeZ4L3++uFrajVzdjeKpLe8ZXK1FQGbcABSeeEFaePG+HX33ivdfnv29RTBsE04XsQAkMhDD0kf/Wj8umeekYIg83KcwAgCwFBRJH3wg2bMMCp8P/xhqd836wnf5OiAASzT6UhXXBG/7qGHTPji3NABA5hz772m240L3xdeMN0u4Xt+CGCg5E6cMKHredIddwxft2vX/NndDRsmV5/LCGCgpH7yk/kLcUZ59FETurt3T6auMmEGDJTMmjXmQ5WjbNtmgnfNmsnUVFZ0wEAJPPPM/JhhVPju2WO63UOHCN9JIIABh915pwnd17529LpDh0zwfv7zk6kLBiMIwDFnziTvXvt9E9Cwgw4YcMQjj5gwjQvf73xn/jQD4WsXHTBQcDt2SH/5S/y6o0fLffVjHhHAQAE9/7x08cXx6669VnrssezrwblhBAEUyHe/a8YGceG7b58ZMRC++UYHDORcFEmVhK3S6dPSav5fXRh0wEBOPfGE6Xbjwvf22+c31QjfYuHXBeTMFVeY28jiPP20dOWVmZeDDBHAQA6cPCkt+QzcUCk+YoOcYwQBWDTYVIsL3x/+cH7MAHfQAQMWJH0B4tixZMfNUEx0wEuEYaggCFSpVBQEgcIwtF0SHNHpzF+IE2fQ7RK+biOAFwjDUI1GQ91uV1EUqdvtqtFoEMI4L5/8ZLKvTPzyl4wZyobP0i8QBIG63e6y577vq5NkWxr4vzRnd8+ckVatyrYe2DXss/R0wAvMzMykeg43nc8Yau/eZGd3P/CB+W6X8C0vNuEWqNVqK3bAtVrNQjWwYTCG6vV6kjQ3hpKker0+9OfWrZNmZ+P//OlpacuWsZQKB9ABL9BqtVRdch6oWq2q1WpZqgiT1mw258J3oNfrqdlsLlv74ovzm2px4TvodglfLEQAL1Cv19Vut+X7vjzPk+/7arfbIzsfuCXJGOqee0zoxn0ZePduNtUwGgG8RL1eV6fTUb/fV6fTIXxLZti4qVarzXW7KzTDixw/bkJ3164MCswARy/tIYCBBZaPoa6SFKnb7Yz8uVe8Yr7bvfDCLCscL45e2sUxNGCJMAz1uc9t1alT18eu3b9feve7J1BURjh6ORnDjqFxCgL4v/mPWcaPnVz5mCVHL+1iBIHSu//+ZB+z3LnTvY9Zjpp5I3t0wCitpCE6MyNdfnm2tdjSarUWnXuWOHo5SXTAKJV//Sv9hTiuhq/E0UvbCGCUwkc+YkL3Na8Zve6rXy3f2V2OXtrDCAJOSzpm6PXM68TAJNEBwzm/+EX6MQPhCxvogOGMpN3u3r3S+96XbS1AEgQwCq3Xky64INnaMs11UQyMIFBIjYbpeOPC1/fLt6mG4qADRqEkHTP84x/xnwACbKMDRu49/nj6TTXCF0VAACO3BqF79dWj133lK4wZUEwEsEXcw7rc4J6FJN3uSy+Z9ffck31dQBYIYEu4h3Wxb30r2ccspflud+3a7OsCssR9wJZwD6uRdFNt3z7pppuyrQXICvcB50yZ72E9ckS67LJka5nrwmWMICwp4z2sb3yj6XjjwveVr2RTDeVAAFuy/Ntj7t7DOthUO3Ro9LpnnzWh+9xzk6kLsI0AtsT1e1j37Ut/djfuqkjANWzCYaySbqrdfbfkYLMPrIhNOGRm/mOWydauWpVtPUBRMILAObvzzmQfs5TmxwyELzCPDhipJR0z/P730jvekW0tQJERwEik00l+wQ3Hx4BkGEFgpOuuMx1vXPju2MHZXSAtOmCsKOmY4T//kTZuzLYWwFV0wJjzm9+kP7tL+ALnjgDGXOh+6ENxK3fK9wNNTZXzxjZg3BhBlNTsbPJPsa9bd4FOnuxJkrpdqdFoSJIzb+0BttABl8yXvmS63bjw3bjRjBh8P5gL34Fer6dms5lhlUA50AGXRNJNtelpacuW+X8v87WZQNbogB321FPpN9UWhq9UzmszgUkhgB10ySUmdF//+tHr7rgj/uxuma7NBCaNEYQjoijZ99Qk6eRJ6eUvT7Z2sNHWbDY1MzOjWq2mVqvFBhwwBlxHWXBTU9LOncnW8pYaYAfXUTom6abar3+d5HwvABuYARdEGIaq1a5OvalG+AL5RQAXwFvf2tWnP13X4cOjP6p2zTVciAMUCSOIHJvvdP2R6w4fljZvzrwcAGNGB5wzBw8mP7vreRVFEeELFBUBnBOD0N2+bJ90qbsleZI8XoYACo4RhEX9fvJvpK1bt14nTx6f+3dehgCKjw7Ygr17TbebJHwHm2oPPPA9+b4vz/Pk+77a7TYvQwAFRwBP0MteZoL3/e8fve4Pf1h+mqFer6vT6ajf76vT6RC+McIwVBAEqlQqCoJAYcgdxsgfRhAZe/FFacOGZGs5PjYeYRiq0Wio1xvcYdzlDmPkEh1wRlot0+3Ghe+3v83Z3XFrNptz4TvAHcbIIzrgMUv6ivDx49KFF2ZbS1lxhzGKgg54DP7+92Rndy++eL7bJXyzwx3GKAoC+DzceKMJ3W3bRq/bv9+E7rFjEylr7Iq2ocUdxigKRhApnTkjrVmTbG2/n3wkkVdF3NDiDmMUBfcBJ/Tzn0sf/3j8us98RvrRj7KvZ1KCIFC321323Pd9dTqdyRcEFBD3AZ+jpB2sqxfisKEFZIcZ8AqOHEn/MUsXw1diQwvIEgG8wAMPmNC97LLR6/bsKc/ZXTa0gOwwglDyMcPsrHmduEzY0AKyU9pNuH//W3rVq+LXbd1qzvkCwLkatglXuhHE1JTpeOPCd3rajBjyFr5FO5MLYLhSjCDOnpV27JD++tf4tXme6xbxTC6A4ZzugB9/3HS7q1ePDt+pKbubakm7Wi6ZAdziZAf8ta9J3/jG6DWbNkkzM9K6dZOpaZg0XS1ncgG3ONMBnzghrV1rOt5R4bt7t+l0jxyxH75Suq6WM7mAWwofwA8/bEL3oouk06eHr3vqKRO8u3ZNrrYk0nS1nMkF3FLIAI4i6ZZbTPDefPPwdTfeaDbgokh63esmVl4qabraer2udrvNt+EARxQqgJ991oRupSI9+ODwdQ8+aEL3d78za/MsbVfLt+EAd+Q8nox22wTv5ZePXnfsmAnej31sMnWNA10tUF65fhNudjZ+o+y226T77ptMPQBwLgp5HeVPfzr8v/35z9Kb3zy5WgBg3HIdwG96k7R+vfm0uyQFgfTkk+W7EAeAm3IdwNdcY16WOHVKuvRS29UAwHjlOoAlacMG2xUAQDYKcQoCAFxEAAOAJaUOYO7WBWBT7mfAWeFuXQC2lbYD5m5dALaVNoC5WxeAbaUNYO7WLS5m93BFaQPYlbt1yxZGg9l9t9tVFEVzs3vX/95wVBRFif+54YYbIpdMTU1Fvu9HnudFvu9HU1NTtktKZWpqKqpWq5GkuX+q1erIv0fR/86+7y/6+w7+8X3fdmnAUJIORCtkaq5vQ8NoQRCo2+0ue+77vjqdzrLnS09+SKbrL9L1l5VKRSv9b9bzPPX7fQsVAfGG3YZW2hGEC9JuJLpw8oPZPVxCABdY2jBy4eSHK7N7QCKACy1tGLnQPfIFEbiEAC6wtGHkSvfId/HgikIEcNmOWqWRJozoHoF8yf0pCBd27gGUW2FPQbiwcw8AK8l9ALuwcw8AK8l9ALuwcw8AK8l9ALuycw8AS+U6gMMwnJsBr1q1SpLYuS8JTr6gDHL7RYylpx/Onj071/kSvm7jayUoi9weQ0t70Qzcwe8erincMTROP5QXv3uURW4DmNMP5cXvHmWR2wDm9EN58btHWeQ2gLm3oLz43aMscrsJBwCuKNwmHAC4jgAGAEsIYACwhAAGAEsIYACwJNUpCM/zjkha/o4oAGAUP4qiS5c+TBXAAIDxYQQBAJYQwABgCQEMAJYQwABgCQEMAJYQwABgCQEMAJYQwABgCQEMAJb8D/oRZi/fc6N0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The Root mean squared error\n",
    "print(\"RMSE: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(diabetes_y_test, diabetes_y_pred)))\n",
    "# The MAE\n",
    "print(\"MAE: %.2f\"\n",
    "      % mean_absolute_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R2: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
