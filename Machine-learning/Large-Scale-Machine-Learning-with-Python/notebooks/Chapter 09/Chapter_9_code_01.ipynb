{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing data within the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read-only variables (broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: let's encode the gender found in the demographic data\n",
    "# As a hot encode. Note: the association should be the same\n",
    "# on every machine in the cluster, requiring a shared mapping\n",
    "\n",
    "one_hot_encoding = {\"M\": (1, 0, 0),\n",
    "                    \"F\": (0, 1, 0),\n",
    "                    \"U\": (0, 0, 1)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0), (0, 1, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0), (0, 0, 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender one-hot-encoding\n",
    "(sc.parallelize([\"M\", \"F\", \"U\", \"F\", \"M\", \"U\"])\n",
    "   .map(lambda x: one_hot_encoding[x])\n",
    "   .collect())\n",
    "\n",
    "# The command above works only in the single node configuration\n",
    "# since the variable \"one_hot_encoding\" is defined only on this machine\n",
    "# On a multi-node cluster, it will raise a Java error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0), (0, 1, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0), (0, 0, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1: include the encoding map in the .map() function \n",
    "# In this way, all the nodes will see it\n",
    "\n",
    "def map_ohe(x):\n",
    "    ohe = {\"M\": (1, 0, 0),\n",
    "           \"F\": (0, 1, 0),\n",
    "           \"U\": (0, 0, 1)\n",
    "          }\n",
    "    return ohe[x]\n",
    "\n",
    "sc.parallelize([\"M\", \"F\", \"U\", \"F\", \"M\", \"U\"]).map(map_ohe).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0), (0, 1, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0), (0, 0, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2: broadcast the map to all the nodes.\n",
    "# All of them will be able to read-only it\n",
    "\n",
    "bcast_map = sc.broadcast(one_hot_encoding)\n",
    "\n",
    "def bcast_map_ohe(x, shared_ohe):\n",
    "    return shared_ohe[x]\n",
    "\n",
    "(sc.parallelize([\"M\", \"F\", \"U\", \"F\", \"M\", \"U\"])\n",
    " .map(lambda x: bcast_map_ohe(x, bcast_map.value))\n",
    " .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcast_map.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write-only variables (broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of empty lines is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's coint the empty line in a file\n",
    "\n",
    "print \"The number of empty lines is:\"\n",
    "\n",
    "(sc.textFile('file:///home/vagrant/datasets/hadoop_git_readme.txt')\n",
    "   .filter(lambda line: len(line) == 0)\n",
    "   .count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the file there are 31 lines\n",
      "And 6 lines are empty\n"
     ]
    }
   ],
   "source": [
    "# Let's count the lines in a file, and at the same time,\n",
    "# count the empty ones\n",
    "\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def split_line(line):   \n",
    "    if len(line) == 0:\n",
    "        accum.add(1)\n",
    "    return 1\n",
    "\n",
    "tot_lines = (\n",
    "    sc.textFile('file:///home/vagrant/datasets/hadoop_git_readme.txt')\n",
    "      .map(split_line)\n",
    "      .count())\n",
    "\n",
    "empty_lines = accum.value\n",
    "\n",
    "\n",
    "print \"In the file there are %d lines\" % tot_lines\n",
    "print \"And %d lines are empty\" % empty_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real world example with broadcast and accumulator\n",
    "### train multiple classifiers and select the best one, accumulating the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1: load the dataset\n",
    "# note: if the dataset is large, you should read the next section\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "bcast_dataset = sc.broadcast(load_iris())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 2: create an accumulator that stores the errors in a list\n",
    "\n",
    "from pyspark import AccumulatorParam\n",
    "\n",
    "class ErrorAccumulator(AccumulatorParam):\n",
    "    def zero(self, initialList):\n",
    "        return initialList\n",
    "\n",
    "    def addInPlace(self, v1, v2):\n",
    "        if not isinstance(v1, list):\n",
    "            v1 = [v1]\n",
    "        if not isinstance(v2, list):\n",
    "            v2 = [v2]\n",
    "        return v1 + v2\n",
    "\n",
    "errAccum = sc.accumulator([], ErrorAccumulator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3: create mappers: each of them will use a classifier\n",
    "\n",
    "def apply_classifier(clf, dataset):\n",
    "    \n",
    "    clf_name = clf.__class__.__name__\n",
    "    X = dataset.value.data\n",
    "    y = dataset.value.target\n",
    "    \n",
    "    try:\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        \n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "\n",
    "        return [(clf_name, acc)]\n",
    "\n",
    "    except Exception as e:\n",
    "        errAccum.add((clf_name, str(e)))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DummyClassifier', 0.33333333333333331),\n",
       " ('SGDClassifier', 0.66666666666666663)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "classifiers = [DummyClassifier('most_frequent'), \n",
    "               SGDClassifier(), \n",
    "               PCA(), \n",
    "               MDS()]\n",
    "\n",
    "(sc.parallelize(classifiers)\n",
    "     .flatMap(lambda x: apply_classifier(x, bcast_dataset))\n",
    "     .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The errors are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('PCA', \"'PCA' object has no attribute 'predict'\"),\n",
       " ('MDS',\n",
       "  \"Proximity must be 'precomputed' or 'euclidean'. Got euclidean instead\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"The errors are:\"\n",
    "errAccum.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcast_dataset.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"user_id\":0, \"balance\": 10.0}\r\n",
      "{\"user_id\":1, \"gender\":\"M\", \"balance\": 1.0}\r\n",
      "{\"user_id\":2, \"gender\":\"F\", \"balance\": -0.5}\r\n",
      "{\"user_id\":3, \"gender\":\"F\", \"balance\": 0.0}\r\n",
      "{\"user_id\":4, \"balance\": 5.0}\r\n",
      "{\"user_id\":5, \"gender\":\"M\", \"balance\": 3.0}"
     ]
    }
   ],
   "source": [
    "!cat /home/vagrant/datasets/users.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|   10.0|  null|      0|\n",
      "|    1.0|     M|      1|\n",
      "|   -0.5|     F|      2|\n",
      "|    0.0|     F|      3|\n",
      "|    5.0|  null|      4|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.json(\"file:///home/vagrant/datasets/users.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- balance: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    1.0|     M|      1|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.filter(df['gender'] != 'null')\n",
    "   .filter(df['balance'] > 0)\n",
    "   .select(['balance', 'gender', 'user_id'])\n",
    "   .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    1.0|     M|      1|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.filter('gender is not null')\n",
    "   .filter('balance > 0').select(\"*\").show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    1.0|     M|      1|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('gender is not null and balance > 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    1.0|     M|      1|\n",
      "|   -0.5|     F|      2|\n",
      "|    0.0|     F|      3|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    1.0|     M|      1|\n",
      "|   -0.5|     F|      2|\n",
      "|    0.0|     F|      3|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=[\"gender\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|   10.0|     U|      0|\n",
      "|    1.0|     M|      1|\n",
      "|   -0.5|     F|      2|\n",
      "|    0.0|     F|      3|\n",
      "|    5.0|     U|      4|\n",
      "|    3.0|     M|      5|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill({'gender': \"U\", 'balance': 0.0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|gender|avg(balance)|\n",
      "+------+------------+\n",
      "|     F|       -0.25|\n",
      "|     M|         2.0|\n",
      "|     U|         7.5|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.na.fill({'gender': \"U\", 'balance': 0.0})\n",
    "   .groupBy(\"gender\").avg('balance').show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|  _c1|\n",
      "+------+-----+\n",
      "|     F|-0.25|\n",
      "|     M|  2.0|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT gender, AVG(balance) \n",
    "    FROM users \n",
    "    WHERE gender IS NOT NULL \n",
    "    GROUP BY gender\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sqlContext.table(\"users\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(balance=10.0, gender=None, user_id=0),\n",
       " Row(balance=1.0, gender=u'M', user_id=1),\n",
       " Row(balance=-0.5, gender=u'F', user_id=2),\n",
       " Row(balance=0.0, gender=u'F', user_id=3),\n",
       " Row(balance=5.0, gender=None, user_id=4),\n",
       " Row(balance=3.0, gender=u'M', user_id=5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.table(\"users\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(balance=10.0, gender=None, user_id=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_row = sqlContext.sql(\"SELECT * FROM users\").first()\n",
    "a_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print a_row['balance']\n",
    "print a_row.balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balance': 10.0, 'gender': None, 'user_id': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /tmp/complete_users*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.na.drop().write\n",
    "   .save(\"file:///tmp/complete_users.json\", format='json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28\r\n",
      "4 drwxrwxr-x  2 vagrant vagrant 4096 May 10 20:36 .\r\n",
      "4 drwxrwxrwt 22 root    root    4096 May 10 20:36 ..\r\n",
      "4 -rw-r--r--  1 vagrant vagrant   83 May 10 20:36 part-r-00000-f5728f74-10d9-4c7a-8865-64cb80c7ca0a\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   12 May 10 20:36 .part-r-00000-f5728f74-10d9-4c7a-8865-64cb80c7ca0a.crc\r\n",
      "4 -rw-r--r--  1 vagrant vagrant   82 May 10 20:36 part-r-00001-f5728f74-10d9-4c7a-8865-64cb80c7ca0a\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   12 May 10 20:36 .part-r-00001-f5728f74-10d9-4c7a-8865-64cb80c7ca0a.crc\r\n",
      "0 -rw-r--r--  1 vagrant vagrant    0 May 10 20:36 _SUCCESS\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant    8 May 10 20:36 ._SUCCESS.crc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -als /tmp/complete_users.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|balance|gender|user_id|\n",
      "+-------+------+-------+\n",
      "|    0.0|     F|      3|\n",
      "|    3.0|     M|      5|\n",
      "|    1.0|     M|      1|\n",
      "|   -0.5|     F|      2|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\n",
    "    \"SELECT * FROM json.`file:///tmp/complete_users.json`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.na.drop().write.save(\n",
    "    \"file:///tmp/complete_users.parquet\", format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44\r\n",
      "4 drwxrwxr-x  2 vagrant vagrant 4096 May 10 20:36 .\r\n",
      "4 drwxrwxrwt 23 root    root    4096 May 10 20:36 ..\r\n",
      "4 -rw-r--r--  1 vagrant vagrant  376 May 10 20:36 _common_metadata\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   12 May 10 20:36 ._common_metadata.crc\r\n",
      "4 -rw-r--r--  1 vagrant vagrant 1082 May 10 20:36 _metadata\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   20 May 10 20:36 ._metadata.crc\r\n",
      "4 -rw-r--r--  1 vagrant vagrant  750 May 10 20:36 part-r-00000-810195c2-ffa9-4a54-add7-61e6a7c92095.gz.parquet\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   16 May 10 20:36 .part-r-00000-810195c2-ffa9-4a54-add7-61e6a7c92095.gz.parquet.crc\r\n",
      "4 -rw-r--r--  1 vagrant vagrant  746 May 10 20:36 part-r-00001-810195c2-ffa9-4a54-add7-61e6a7c92095.gz.parquet\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant   16 May 10 20:36 .part-r-00001-810195c2-ffa9-4a54-add7-61e6a7c92095.gz.parquet.crc\r\n",
      "0 -rw-r--r--  1 vagrant vagrant    0 May 10 20:36 _SUCCESS\r\n",
      "4 -rw-rw-r--  1 vagrant vagrant    8 May 10 20:36 ._SUCCESS.crc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -als /tmp/complete_users.parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "rdd_gender = \\\n",
    "    sc.parallelize([Row(short_gender=\"M\", long_gender=\"Male\"),\n",
    "                    Row(short_gender=\"F\", long_gender=\"Female\")])\n",
    "\n",
    "(sqlContext.createDataFrame(rdd_gender)\n",
    "           .registerTempTable(\"gender_maps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|long_gender|short_gender|\n",
      "+-----------+------------+\n",
      "|       Male|           M|\n",
      "|     Female|           F|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.table(\"gender_maps\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------+\n",
      "|balance|long_gender|user_id|\n",
      "+-------+-----------+-------+\n",
      "|    1.0|       Male|      1|\n",
      "|    3.0|       Male|      5|\n",
      "|   -0.5|     Female|      2|\n",
      "|    0.0|     Female|      3|\n",
      "+-------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT balance, long_gender, user_id \n",
    "    FROM parquet.`file:///tmp/complete_users.parquet` \n",
    "    JOIN gender_maps ON gender=short_gender\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'gender_maps', u'users']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.tableNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for table in sqlContext.tableNames():\n",
    "    sqlContext.dropTempTable(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
