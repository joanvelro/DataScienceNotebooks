{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Model Evaluation\n",
    "\n",
    "In this notebook we will implement several different machine learning algorithms on the manual engineered features after feature selection. There are a total of around 350 features after the engineering plus selection process. We will test several different sklearn algorithms as well as the Gradient Boosting Machine as implemented in LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (307511, 342)\n",
      "Testing shape:  (48744, 342)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/m_train_small.csv')\n",
    "test = pd.read_csv('../input/m_test_small.csv')\n",
    "\n",
    "train_labels = train['TARGET']\n",
    "train_ids = train['SK_ID_CURR']\n",
    "test_ids = test['SK_ID_CURR']\n",
    "\n",
    "train = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "test = test.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "submission = pd.DataFrame({'SK_ID_CURR' : test_ids})\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')),\n",
    "                     ('scaler', MinMaxScaler(feature_range = (0, 1)))])\n",
    "                     \n",
    "train = pipeline.fit_transform(train)\n",
    "test = pipeline.transform(test)\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model, name):\n",
    "    predictions = model.predict_proba(test)[:, 1]\n",
    "    submission['TARGET'] = predictions\n",
    "    submission.to_csv('%s_submission.csv' % name, index = False)\n",
    "    print('Submission saved to %s_submission.csv' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(Cs = 20, n_jobs = -1, cv = 3, verbose = 1)\n",
    "logreg.fit(train, train_labels)\n",
    "make_submission(logreg, name = 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 1000, n_jobs = -1, verbose = 1)\n",
    "rf.fit(train, train_labels)\n",
    "make_submission(rf, name = 'rf')\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators = 1000, n_jobs = -1, verbose = 1)\n",
    "et.fit(train, train_labels)\n",
    "make_submission(et, name = 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5602          120.59m\n",
      "         2           0.5594          115.26m\n",
      "         3           0.5586          113.31m\n",
      "         4           0.5578          112.12m\n",
      "         5           0.5570          111.62m\n",
      "         6           0.5562          110.64m\n",
      "         7           0.5555          110.10m\n",
      "         8           0.5548          111.30m\n",
      "         9           0.5541          111.37m\n",
      "        10           0.5534          110.65m\n",
      "        20           0.5475          107.29m\n",
      "        30           0.5427          106.10m\n",
      "        40           0.5388          105.57m\n",
      "        50           0.5354          104.42m\n",
      "        60           0.5325          104.10m\n",
      "        70           0.5299          103.60m\n",
      "        80           0.5277          103.66m\n",
      "        90           0.5257          103.11m\n",
      "       100           0.5239          102.47m\n",
      "       200           0.5112           92.02m\n",
      "       300           0.5033           80.92m\n",
      "       400           0.4978           70.39m\n",
      "       500           0.4936           58.64m\n",
      "       600           0.4905           46.67m\n",
      "       700           0.4880           34.88m\n",
      "       800           0.4858           23.19m\n",
      "       900           0.4839           11.58m\n",
      "      1000           0.4822            0.00s\n",
      "Submission saved to gbm_submission.csv\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators = 1000, learning_rate = 0.01, verbose = 1)\n",
    "gbm.fit(train, train_labels)\n",
    "make_submission(gbm, name = 'gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to lgb_gbm_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create the model with several hyperparameters\n",
    "lgb_gbm = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 1000, \n",
    "                             learning_rate = 0.01, class_weight = 'balanced', n_jobs = -1, verbose = 200)\n",
    "lgb_gbm.fit(train, train_labels)\n",
    "make_submission(lgb_gbm, 'lgb_gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the submissions \n",
    "logreg_sub = pd.read_csv('logreg_submission.csv')\n",
    "rf_sub = pd.read_csv('rf_submission.csv')\n",
    "et_sub = pd.read_csv('et_submission.csv')\n",
    "gbm_sub = pd.read_csv('gbm_submission.csv')\n",
    "lgb_gbm_sub = pd.read_csv('lgb_gbm_submission.csv')\n",
    "\n",
    "average_sub = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': 0})\n",
    "\n",
    "# Average the preditions together\n",
    "average_sub['TARGET'] = (rf_sub['TARGET'] + et_sub['TARGET'] + gbm_sub['TARGET'] + lgb_gbm_sub['TARGET']) / 4\n",
    "\n",
    "average_sub.to_csv('average_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression = 0.768\n",
    "Random Forest with 1000 trees = 0.708\n",
    "Extra Trees with 1000 trees = 0.725\n",
    "Gradient Boosting Machine in Scikit-Learn with 1000 trees = \n",
    "Gradient Boosting Machine in LightGBM with 1000 trees = \n",
    "Average of all Models =\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
